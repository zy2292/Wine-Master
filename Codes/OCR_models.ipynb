{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image_to_string(image, config = '--psm 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: baseline\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    text = pytesseract.image_to_string(image, config = '--psm 3', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_1.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: change black/white\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    imageWhite = PIL.ImageOps.invert(imageOriginal)\n",
    "    text = pytesseract.image_to_string(imageWhite, config = '--psm 3', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_2.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: with canny edge detection and bilateralFilter (to preserve the edge)\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    bilateral = cv2.bilateralFilter(image, d=10, sigmaColor=10*2, sigmaSpace=10/2)\n",
    "    edges = cv2.Canny(bilateral,100,200)\n",
    "    text = pytesseract.image_to_string(edges, config = '--psm 3', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_3.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: bilateralFilter(image, d=8, sigmaColor=2*2, sigmaSpace=2/2)\n",
    "# Low contrast\n",
    "# Flourish font (open)\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    bilateral = cv2.bilateralFilter(image, d=8, sigmaColor=2*2, sigmaSpace=2/2)\n",
    "    edges = cv2.Canny(bilateral,100,200)\n",
    "    text = pytesseract.image_to_string(edges, config = '--psm 3', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_4.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: bilateralFilter(image, d=15, sigmaColor=15*2, sigmaSpace=15/2)\n",
    "# Text with shadow (open)\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    bilateral = cv2.bilateralFilter(image, d=15, sigmaColor=15*2, sigmaSpace=15/2)\n",
    "    edges = cv2.Canny(bilateral,100,200)\n",
    "    text = pytesseract.image_to_string(edges, config = '--psm 3', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_5.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image_to_string(image, config = '--psm 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6: image_to_string(image, config = '--psm 4') for a single column of text of variable sizes\n",
    "# Bold character in a single column\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    text = pytesseract.image_to_string(image, config = '--psm 4', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_6.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 7: change black/white\n",
    "# Bold character in a single column\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    imageWhite = PIL.ImageOps.invert(imageOriginal)\n",
    "    text = pytesseract.image_to_string(imageWhite, config = '--psm 4', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_7.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8: bilateralFilter(image, d=15, sigmaColor=15*2, sigmaSpace=15/2)\n",
    "# High noise with variable text sizes: for large font size\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    bilateral = cv2.bilateralFilter(image, d=15, sigmaColor=15*2, sigmaSpace=15/2)\n",
    "    edges = cv2.Canny(bilateral,100,200)\n",
    "    text = pytesseract.image_to_string(edges, config = '--psm 4', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_8.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 9: bilateralFilter(image, d=8, sigmaColor=2*2, sigmaSpace=2/2)\n",
    "# High noise with variable text sizes: for small font size\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    bilateral = cv2.bilateralFilter(image, d=8, sigmaColor=2*2, sigmaSpace=2/2)\n",
    "    edges = cv2.Canny(bilateral,100,200)\n",
    "    text = pytesseract.image_to_string(edges, config = '--psm 4', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_9.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image_to_string(image, config = '--psm 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 10: image_to_string(image, config = '--psm 5') for a single uniform block of vertically aligned text\n",
    "# Text positions not horizontal (open)\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    text = pytesseract.image_to_string(image, config = '--psm 5', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_10.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image_to_string(image, config = '--psm 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 11: image_to_string(image, config = '--psm 6') for a single uniform block of text\n",
    "# Part of the text not recognized\n",
    "# Text positions not horizontal (open)\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    text = pytesseract.image_to_string(image, config = '--psm 6', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_11.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 12: bilateralFilter(image, d=8, sigmaColor=2*2, sigmaSpace=2/2)\n",
    "# Character of different colors\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    bilateral = cv2.bilateralFilter(image, d=8, sigmaColor=2*2, sigmaSpace=2/2)\n",
    "    edges = cv2.Canny(bilateral,100,200)\n",
    "    text = pytesseract.image_to_string(edges, config = '--psm 6', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_12.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 13: bilateralFilter(image, d=15, sigmaColor=15*2, sigmaSpace=15/2)\n",
    "# One large character per line\n",
    "text_unstructure={}\n",
    "for i in range(1,221):\n",
    "    Num = i\n",
    "    imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "    image = np.asarray(imageOriginal)\n",
    "\n",
    "    imageWhite = PIL.ImageOps.invert(imageOriginal)\n",
    "    text = pytesseract.image_to_string(imageWhite, config = '--psm 4', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "    text_unstructure[i] = text\n",
    "\n",
    "with open(os.path.join(\"./Data/OCR\", \"model_13.json\"), 'w') as fp:\n",
    "    json.dump(text_unstructure, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_unstructure={}\n",
    "# for i in range(1,221):\n",
    "#     Num = i\n",
    "#     imageOriginal = Image.open('./Data/image_scraper/train_'+ str(Num) +'.jpg').convert(\"L\")\n",
    "#     image = np.asarray(imageOriginal)\n",
    "\n",
    "#     text = pytesseract.image_to_string(image, config = '--psm 3', lang = 'eng+fra+deu+ita+spa+por+afr')\n",
    "#     text_unstructure[i]=text\n",
    "\n",
    "# file = open(os.path.join(\"./Data/OCR\", \"model_1\"), 'w')\n",
    "# for item in text_unstructure:\n",
    "#     file.write(\"%s\\n\" % item)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
